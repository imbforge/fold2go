
executor {
    name      = 'slurm'
    jobName   = { task.process }
}

mail {
    smtp.host = 'mailgate.zdv.uni-mainz.de'
    smtp.port = 25
    smtp.user = { params.EMAIL }
}

process {
    container     = { "imbforge/fold2go/${moduleDir.name}:${workflow?.revision ?: 'next'}" }
    errorStrategy = 'retry'
    maxRetries    = 3
    shell         = ['/usr/bin/env', 'bash', '-ue', '-o', 'pipefail']
    cache         = 'lenient' // workaround for lagging nfs timestamps

    queue = { task.time <= 5.h ? 'short' : 'long' }

    withLabel: 'gpu' {
        queue            = 'gpulong' // { task.time <= 5.h ? 'gpushort' : 'gpulong' }
        clusterOptions   = '--gres=gpu:1'
        containerOptions = '--nv --nvccli --writable-tmpfs'
    }

    withLabel: 'ssd' {
        // spinning disks via NFS are prohibitive for multiple sequence alignments
        // unfortunately, there are no SSDs mounted on hpc[1-3], so we need to send those msa jobs to the gpu queue as well
        queue = 'gpulong' // { task.time <= 5.h ? 'gpushort' : 'gpulong' }

        // limit number of concurrent tasks to leave room for efficient placement of gpu jobs
        maxForks = 8
    }
}

singularity {
    enabled      = true
    registry     = 'registry.gitlab.rlp.net'
    libraryDir   = "/fsimb/common/singularity_tools/fold2go"
    //envWhitelist = "NVIDIA_VISIBLE_DEVICES=1,TF_FORCE_UNIFIED_MEMORY=1,XLA_PYTHON_CLIENT_MEM_FRACTION=4.0"
}

// when a run is terminated via GUI, the jupyter-server is not stopped, which leads to a 500 error
// workaround this by manually stopping the jupyter-server, which will shut the proxy down as well
// FIXME: once https://github.com/jupyterhub/jupyter-server-proxy/pull/395 is merged, this can be handled programmatically
if ( System.getenv('JUPYTERHUB_SERVICE_URL') ) {
    workflow.onComplete = { "jupyter-server stop ${new URL(System.getenv('JUPYTERHUB_SERVICE_URL')).getPort()}".execute() }
}